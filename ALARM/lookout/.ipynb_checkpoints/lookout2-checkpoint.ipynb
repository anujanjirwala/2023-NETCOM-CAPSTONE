{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a581001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[157]:\n",
    "\n",
    "\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import copy\n",
    "from scipy.interpolate import interp1d\n",
    "import time\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "import os\n",
    "import sys\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder   \n",
    "from sklearn.metrics.pairwise import manhattan_distances, euclidean_distances\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "sys.path.append(\"../xstream\")\n",
    "from xstream import *\n",
    "import os\n",
    "\n",
    "\n",
    "class Parameters():\n",
    "    def __init__(self, \n",
    "                 json_file_name,\n",
    "                 ):\n",
    "        with open(json_file_name, 'r') as openfile:\n",
    "            json_ = json.load(openfile)\n",
    "        self.dataset_name = json_[\"dataset_name\"]\n",
    "        self.has_label = json_[\"has_label\"]\n",
    "        self.top_features = json_[\"top_features\"]\n",
    "\n",
    "\n",
    "#encode the categorical features to numbers with LabelEncoder\n",
    "def encode_catgorical_column(data,column):\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    return le\n",
    "\n",
    "\n",
    "\"\"\" Definition of Plot \"\"\"\n",
    "class Plot:\n",
    "\tdef __init__( self, id ):\n",
    "\t\tself.id = id\n",
    "\t\tself.value = 0.0\n",
    "\n",
    "\tdef get_id( self ): # Unique identifier of the plot\n",
    "\t\treturn self.id\n",
    "\n",
    "\tdef get_value( self ): # Total influence of the plot\n",
    "\t\treturn self.value\n",
    "\n",
    "\tdef update_value( self, value ):\n",
    "\t\tself.value = value\n",
    "\n",
    "def get_topk_prediction(scores, top_k):\n",
    "    ind = np.argpartition(scores, -top_k)[-top_k:]\n",
    "    return ind\n",
    "\n",
    "\n",
    "def load_all_result(path):\n",
    "    \"\"\"\n",
    "    Read all results from path\n",
    "    \"\"\"\n",
    "    return pd.read_csv(path, delimiter=\",\",index_col = \"index\")\n",
    "\n",
    "\n",
    "def get_inference(all_result, X, feature_names=None):\n",
    "    \"\"\"\n",
    "    Gets  explain value information\n",
    "    :param result: all_results procesed by Xstream\n",
    "    :param feature_name: optional feature names\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    col_names = list(all_result.columns)\n",
    "    if feature_names is None:\n",
    "        feature_names = list(X.columns)\n",
    "  \n",
    "    explain_ = [feat + \"_ex\" for feat in feature_names]     \n",
    "\n",
    "    #print(feature_names)\n",
    "    assert len(explain_) == len(feature_names)\n",
    "    assert len(explain_) == len(list(X.columns))\n",
    "    for i in explain_:\n",
    "        assert(i in col_names)\n",
    "   \n",
    "    outlier_explain = all_result[explain_]\n",
    "    outlier_explain.index.names = [\"index\"]\n",
    "    return outlier_explain\n",
    "\n",
    "def get_anomaly_score_data(all_result):\n",
    "    \"\"\"\n",
    "    get xstream anomaly scores\n",
    "    :param result: all_results procesed by Xstream\n",
    "    :return: array with anomaly scores\n",
    "    \"\"\"\n",
    "    assert \"anomaly_scores\" in list(all_result.columns)\n",
    "    return  all_result[\"anomaly_scores\"]\n",
    "\n",
    "# Get scatter plot outlier scores and figure\n",
    "def get_scores(original_data, feature_X, feature_Y, make_plot=True, get_log = False):\n",
    "    data = original_data[:,(feature_X, feature_Y)]\n",
    "    #print(data.shape)\n",
    "    #you need to feed a subset of features, retraining is required\n",
    "    new_model = XStream()\n",
    "    new_model.fit(data)\n",
    "    #print(\"We acquire the anomaly scores\")\n",
    "    \n",
    "    scores = new_model.predict_proba(data)\n",
    "    scores = minmax_scale(scores)\n",
    "    ids = list(range(data.shape[0]))\n",
    "    tuples = [(ids[i], scores[i]) for i in range(0, len(ids))]\n",
    "    scores = sorted( tuples, key = lambda x: x[1], reverse = True )\n",
    "    return scores\n",
    "\n",
    "def findPairs(n): \n",
    "    return list(Counter(combinations(n, 2)))\n",
    "\n",
    "\n",
    "def print_format(ls):\n",
    "    str_= str(ls)\n",
    "    str_ = str_.replace(\" \",\"\")\n",
    "    str_ = str_.replace(\",\",\"_\")\n",
    "    str_ = str_[1:-1]\n",
    "    return str_\n",
    "\n",
    "#load data, feature importances, y and etc.\n",
    "dataset_name = \"pkdd1998\"\n",
    "has_label = True\n",
    "topk = 70\n",
    "top_features = 10\n",
    "all_result = load_all_result(\"../data/%s/concatenate_result.txt\" % dataset_name)\n",
    "original_data = load_all_result(\"../data/%s/generated_synthetic.txt\"% dataset_name)\n",
    "if has_label:\n",
    "    feature_names = list(original_data.columns)[0:-1]\n",
    "else:\n",
    "    feature_names = list(original_data.columns)\n",
    "\n",
    "X = original_data[feature_names]\n",
    "data_index = list(X.index)\n",
    "cat_dim_lst = []\n",
    "for idx,ival in enumerate(X.iloc[0]):\n",
    "    if type(ival) == str:\n",
    "        cat_dim_lst.append(list(X.columns)[idx])\n",
    "\n",
    "explanation_value = get_inference(all_result= all_result, \n",
    "                                    X= X,\n",
    "                                    feature_names=feature_names)\n",
    "scores = get_anomaly_score_data(all_result = all_result)\n",
    "anomaly_scores = np.array(scores)\n",
    "scores_index = list(scores.index)\n",
    "\n",
    "anomaly_index = [int(item) for item in scores_index]\n",
    "normal_index = [int(item) for item in data_index if item not in scores_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fdf9f161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_ex</th>\n",
       "      <th>operation_ex</th>\n",
       "      <th>amount_ex</th>\n",
       "      <th>balance_ex</th>\n",
       "      <th>bank_ex</th>\n",
       "      <th>k_symbol_ex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.017209</td>\n",
       "      <td>0.060122</td>\n",
       "      <td>0.054827</td>\n",
       "      <td>0.040790</td>\n",
       "      <td>0.030677</td>\n",
       "      <td>0.037336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>0.018331</td>\n",
       "      <td>0.059855</td>\n",
       "      <td>0.055882</td>\n",
       "      <td>0.041678</td>\n",
       "      <td>0.029908</td>\n",
       "      <td>0.036211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.017806</td>\n",
       "      <td>0.060225</td>\n",
       "      <td>0.055729</td>\n",
       "      <td>0.041430</td>\n",
       "      <td>0.030056</td>\n",
       "      <td>0.036145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>0.017932</td>\n",
       "      <td>0.059831</td>\n",
       "      <td>0.055426</td>\n",
       "      <td>0.041261</td>\n",
       "      <td>0.030128</td>\n",
       "      <td>0.036651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>0.017932</td>\n",
       "      <td>0.059831</td>\n",
       "      <td>0.055426</td>\n",
       "      <td>0.041261</td>\n",
       "      <td>0.030128</td>\n",
       "      <td>0.036651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.017796</td>\n",
       "      <td>0.060153</td>\n",
       "      <td>0.055655</td>\n",
       "      <td>0.041285</td>\n",
       "      <td>0.052002</td>\n",
       "      <td>0.036234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.055445</td>\n",
       "      <td>0.041103</td>\n",
       "      <td>0.052033</td>\n",
       "      <td>0.036670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.017743</td>\n",
       "      <td>0.060431</td>\n",
       "      <td>0.055574</td>\n",
       "      <td>0.041320</td>\n",
       "      <td>0.030011</td>\n",
       "      <td>0.059243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>0.017796</td>\n",
       "      <td>0.060153</td>\n",
       "      <td>0.055655</td>\n",
       "      <td>0.041285</td>\n",
       "      <td>0.052002</td>\n",
       "      <td>0.036234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>0.018331</td>\n",
       "      <td>0.059855</td>\n",
       "      <td>0.055882</td>\n",
       "      <td>0.041678</td>\n",
       "      <td>0.029908</td>\n",
       "      <td>0.059181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        type_ex  operation_ex  amount_ex  balance_ex   bank_ex  k_symbol_ex\n",
       "index                                                                      \n",
       "162    0.017209      0.060122   0.054827    0.040790  0.030677     0.037336\n",
       "442    0.018331      0.059855   0.055882    0.041678  0.029908     0.036211\n",
       "226    0.017806      0.060225   0.055729    0.041430  0.030056     0.036145\n",
       "1028   0.017932      0.059831   0.055426    0.041261  0.030128     0.036651\n",
       "1020   0.017932      0.059831   0.055426    0.041261  0.030128     0.036651\n",
       "...         ...           ...        ...         ...       ...          ...\n",
       "340    0.017796      0.060153   0.055655    0.041285  0.052002     0.036234\n",
       "1002   0.017775      0.059616   0.055445    0.041103  0.052033     0.036670\n",
       "281    0.017743      0.060431   0.055574    0.041320  0.030011     0.059243\n",
       "364    0.017796      0.060153   0.055655    0.041285  0.052002     0.036234\n",
       "903    0.018331      0.059855   0.055882    0.041678  0.029908     0.059181\n",
       "\n",
       "[70 rows x 6 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "003a25d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform data with labelencoder\n",
    "X_encoded = deepcopy(X)\n",
    "encoders = []\n",
    "for feat in cat_dim_lst:\n",
    "    encoder = encode_catgorical_column(X_encoded,feat)\n",
    "    encoders.append(encoder)\n",
    "X_encoded = np.array(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "55744f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find clusters\n",
    "#\n",
    "\n",
    "clusters = [\"2 clusters\",\"3 clusters\"] #,\"4 clusters\",\"5 clusters\",\"6 clusters\",\"7 clusters\",\"8 clusters\",\"9 clusters\"]\n",
    "cluster_int_index = [int(col[0]) for col in clusters if col.endswith(\"clusters\")]\n",
    "cluster_indices = {}\n",
    "for cluster in clusters:\n",
    "    for c in all_result[cluster].unique():\n",
    "        cluster_indices[cluster, c] = list((all_result[all_result[cluster] == c].index)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0d4790a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_features = {}\n",
    "\n",
    "for cluster in cluster_indices.keys():\n",
    "    cluster_val = cluster_indices[cluster]\n",
    "    features_list = np.argsort(np.mean(np.array(explanation_value.loc[cluster_val]),axis=0))[::-1][0:top_features]\n",
    "    cluster_features[cluster] = features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cef4dec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('2 clusters', 0): array([1, 2, 5, 3, 4, 0]),\n",
       " ('2 clusters', 1): array([1, 2, 4, 3, 5, 0]),\n",
       " ('3 clusters', 2): array([1, 2, 3, 5, 4, 0]),\n",
       " ('3 clusters', 0): array([1, 2, 4, 3, 5, 0]),\n",
       " ('3 clusters', 1): array([1, 5, 2, 3, 4, 0])}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9d7c6b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▊                                   | 1/5 [04:17<17:08, 257.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████▌                          | 2/5 [08:36<12:55, 258.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████▍                 | 3/5 [13:11<08:52, 266.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████▏        | 4/5 [17:14<04:17, 257.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [21:25<00:00, 257.06s/it]\n"
     ]
    }
   ],
   "source": [
    "cluster_feature_pairs = {}\n",
    "\n",
    "for features_list in cluster_features.keys():\n",
    "    cluster_feature_pairs[features_list] = findPairs(cluster_features[features_list])\n",
    "\n",
    "clusters_rank_plot = {}\n",
    "#from tqdm import tqdm\n",
    "for feature_pairs in tqdm(cluster_feature_pairs.keys()):\n",
    "    cluster_scores = []\n",
    "    for pair in cluster_feature_pairs[feature_pairs]:\n",
    "        cluster_scores.append(get_scores(X_encoded, pair[0],pair[1]))\n",
    "    clusters_rank_plot[feature_pairs] = cluster_scores    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "de413e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': {'CREDIT': 0, 'ISSUE': 1}, 'operation': {'TRANSFER FROM ACCOUNT': 0, 'TRANSFER TO ACCOUNT': 1}, 'bank': {'AB': 0, 'CD': 1, 'EF': 2, 'GH': 3, 'IJ': 4, 'KL': 5, 'MN': 6, 'OP': 7, 'QR': 8, 'ST': 9, 'UV': 10, 'WX': 11, 'YZ': 12}, 'k_symbol': {'DUCHOD': 0, 'POJISTNE': 1, 'SIPO': 2, 'UVER': 3, 'unknown': 4}}\n"
     ]
    }
   ],
   "source": [
    "#from copy import deepcopy\n",
    "clusters_rank_plot2 = {}\n",
    "for i in clusters_rank_plot.keys():\n",
    "    clusters_rank_plot2[str(i)] = deepcopy(clusters_rank_plot[i])\n",
    "\n",
    "isExist = os.path.exists(\"../assets/%s\" % dataset_name)\n",
    "if not isExist:\n",
    "    os.makedirs(\"../assets/%s\" % dataset_name)    \n",
    "    \n",
    "np.savez('../assets/%s/xstream%s.npz' % (dataset_name, print_format(cluster_int_index)), **clusters_rank_plot2, allow_pickle=True)\n",
    "df_xstreams_val = np.load('../assets/%s/xstream%s.npz' % (dataset_name, print_format(cluster_int_index)), allow_pickle=True)\n",
    "\n",
    "#encoder mapping\n",
    "encoder_mapping = {}\n",
    "for i,le in enumerate(encoders):\n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    encoder_mapping[cat_dim_lst[i]] = le_name_mapping\n",
    "print(encoder_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bbe21c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_tuple(val):\n",
    "    sep = val.split(\",\")\n",
    "    if len(sep) >1:\n",
    "        i = sep[0]\n",
    "        i = i.replace(\"('\",\"\")\n",
    "        i = i.replace(\"'\",\"\")\n",
    "        j = sep[1]\n",
    "        j = j.replace(\" \",\"\")\n",
    "        j = j.replace(\"'\",\"\")\n",
    "        j = j.replace(\")\",\"\")\n",
    "        tup = (i, int(j))\n",
    "        return tup\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df_xstreams = {}\n",
    "for key in df_xstreams_val.keys():\n",
    "    tup = str_to_tuple(key)\n",
    "    if tup is not None:\n",
    "        df_xstreams[tup] = df_xstreams_val[key]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def assign_scores(cluster_rank, outliers):\n",
    "    plot_best = {}\n",
    "    for plot_n,plot in enumerate(cluster_rank):\n",
    "        for outlier in plot:\n",
    "            idx = outlier[0]\n",
    "            score = outlier[1]\n",
    "            if idx in outliers: \n",
    "                if idx not in plot_best.keys():\n",
    "                    plot_best[idx]= (plot_n,score)\n",
    "                elif plot_best[idx][1] <= score:\n",
    "                    plot_best[idx] = (plot_n,score)\n",
    "#     print(\"assign_scores\")\n",
    "#     print(plot_best)\n",
    "#     print(len(list(plot_best.keys())))\n",
    "#     print(\"others\")\n",
    "#     print(len(outliers))\n",
    "    return plot_best\n",
    "\n",
    "\n",
    "def LookOut(budget,cluster_rank_plot,sorted_plots,best_graphs,outliers):\n",
    "    budget_best_graphs = best_graphs[0:budget]\n",
    "    budget_plots = []\n",
    "    for plot,score in sorted_plots:\n",
    "        if budget > 0:\n",
    "            budget_plots.append(cluster_rank_plot[plot])\n",
    "            budget-=1\n",
    "        else: break\n",
    "    plot_max = {}\n",
    "    #print(budget_plots)\n",
    "    for key,value in assign_scores(budget_plots,outliers).items():\n",
    "        anomaly_id = key\n",
    "        plot_id = sorted_plots[value[0]][0]\n",
    "        score = value[1]\n",
    "        if plot_id not in plot_max.keys():\n",
    "            plot_max[plot_id] = [score,[anomaly_id]]\n",
    "        else:\n",
    "            plot_max[plot_id][0] += score\n",
    "            plot_max[plot_id][1] += [anomaly_id]\n",
    "#     print(len(plot_max.keys()))\n",
    "#     print(plot_max.keys())\n",
    "#     print(\"budget\")\n",
    "#     print(budget_best_graphs)\n",
    "#     print(\"budget plots\")\n",
    "#     print(len(budget_plots))\n",
    "    return plot_max,budget_best_graphs\n",
    "\n",
    "\n",
    "def plot(budget,cluster_rank_plot,sorted_plots,best_graphs,cluster,outliers,X_index):\n",
    "    lo = LookOut(budget,cluster_rank_plot,sorted_plots,best_graphs,outliers)\n",
    "    #lo[0] is the max_explained values\n",
    "    #lo[1] is the graphs until the maximum budgets\n",
    "    figure_list = []\n",
    "    for plot in lo[1]:\n",
    "        score = lo[0][plot][1]\n",
    "        x,y = cluster_feature_pairs[cluster][plot]\n",
    "        dfx = pd.DataFrame(X_index)\n",
    "        dfx[\"color\"] = [0 if i not in outliers else 1 if i in score else 2 for i in dfx[0]]\n",
    "        newPal = {0 :'black' , 1 :'red', 2 :'cyan'}\n",
    "        fig = plt.figure(figsize = (4,3),dpi = 400)\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        #features = np.arange(X_encoded.shape[1])\n",
    "        #features = np.load(\"data/data/dataset_features.npy\",allow_pickle=True)\n",
    "        plt.xlabel(feature_names[x])\n",
    "        if feature_names[x] in cat_dim_lst:\n",
    "            plt.xticks([encoder_mapping[feature_names[x]][i] for i in encoder_mapping[feature_names[x]].keys()],\\\n",
    "                       list(encoder_mapping[feature_names[x]].keys()),rotation=20) \n",
    "        \n",
    "        plt.ylabel(feature_names[y])\n",
    "        if feature_names[y] in cat_dim_lst:\n",
    "            plt.yticks([encoder_mapping[feature_names[y]][i] for i in encoder_mapping[feature_names[y]].keys()],\\\n",
    "                       list(encoder_mapping[feature_names[y]].keys()),rotation=20) \n",
    "        plt.scatter(X_encoded[:,(x)],X_encoded[:,(y)],c=dfx[\"color\"].map(newPal),edgecolor='black',linewidth=0.3,alpha=0.5)\n",
    "        figure_list.append(fig)\n",
    "    return figure_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[199]:\n",
    "\n",
    "\n",
    "cluster_plot_scores = {}\n",
    "\n",
    "for cluster_ix in df_xstreams.keys():\n",
    "    plot_scores = {}\n",
    "    cluster_rank = df_xstreams[cluster_ix]\n",
    "    outliers = cluster_indices[cluster_ix]\n",
    "    for key,value in assign_scores(cluster_rank,outliers).items():\n",
    "        anomaly_id = key\n",
    "        plot_id = value[0]\n",
    "        score = value[1]\n",
    "        if plot_id not in plot_scores.keys():\n",
    "            plot_scores[plot_id] = [score,[anomaly_id]]\n",
    "        else:\n",
    "            plot_scores[plot_id][0] += score\n",
    "            plot_scores[plot_id][1] += [anomaly_id]\n",
    "\n",
    "    sorted_plots = sorted(plot_scores.items(), key=lambda item: item[1][0],reverse=True)\n",
    "\n",
    "    best_graphs = [plot[0] for plot in sorted_plots]\n",
    "\n",
    "    cluster_plot_scores[cluster_ix]= (cluster_rank,sorted_plots,best_graphs)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f1c0a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster_plot_scores = {}\n",
    "\n",
    "for cluster_ix in df_xstreams.keys():\n",
    "    plot_scores = {}\n",
    "    cluster_rank = df_xstreams[cluster_ix]\n",
    "    outliers = cluster_indices[cluster_ix]\n",
    "    for key,value in assign_scores(cluster_rank,outliers).items():\n",
    "        anomaly_id = key\n",
    "        plot_id = value[0]\n",
    "        score = value[1]\n",
    "        if plot_id not in plot_scores.keys():\n",
    "            plot_scores[plot_id] = [score,[anomaly_id]]\n",
    "        else:\n",
    "            plot_scores[plot_id][0] += score\n",
    "            plot_scores[plot_id][1] += [anomaly_id]\n",
    "    sorted_plots = sorted(plot_scores.items(), key=lambda item: item[1][0],reverse=True)\n",
    "    best_graphs = [plot[0] for plot in sorted_plots]\n",
    "    cluster_plot_scores[cluster_ix]= (cluster_rank,sorted_plots,best_graphs)\n",
    "\n",
    "for key in cluster_plot_scores.keys():\n",
    "    cluster_id = int(key[0][0])\n",
    "    sub_cluster_id = key[1]\n",
    "    a,b,c = cluster_plot_scores[key]\n",
    "    #lo = LookOut(budget,a,b,c)\n",
    "    #print(len(lo[0]),len(lo[1]))\n",
    "    for budget in range(1,6):\n",
    "        figures = plot(budget,a,b,c,key, outliers = cluster_indices[key], X_index = data_index)\n",
    "        for i,figure in enumerate(figures):\n",
    "            fname = \"../assets/\"+dataset_name+\"/{0}-{1}-{2}-{3}-{4}.png\".format(\"lookout\",cluster_id,sub_cluster_id+1,budget, i+1)\n",
    "            figure.savefig(fname,bbox_inches = 'tight')\n",
    "            plt.close(figure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e0b2bd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4df38935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: [1.0, [1043.0]],\n",
       " 3: [8.0, [1049.0, 1052.0, 1044.0, 1040.0, 1047.0, 1048.0, 1058.0, 1059.0]],\n",
       " 5: [3.980896873842468, [1000.0, 1017.0, 1018.0, 1019.0]],\n",
       " 6: [1.7084342468895377, [281.0, 226.0]],\n",
       " 12: [2.959335783855708, [903.0, 162.0, 442.0]],\n",
       " 13: [2.0, [1020.0, 1028.0]],\n",
       " 4: [12.0,\n",
       "  [1021.0,\n",
       "   1024.0,\n",
       "   1026.0,\n",
       "   1027.0,\n",
       "   1029.0,\n",
       "   1032.0,\n",
       "   1033.0,\n",
       "   1034.0,\n",
       "   1035.0,\n",
       "   1036.0,\n",
       "   1037.0,\n",
       "   1038.0]]}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "76f9d9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.04300000e+03, 1.00000000e+00],\n",
       "        [1.04900000e+03, 1.00000000e+00],\n",
       "        [1.05200000e+03, 1.00000000e+00],\n",
       "        ...,\n",
       "        [1.03700000e+03, 0.00000000e+00],\n",
       "        [1.03800000e+03, 0.00000000e+00],\n",
       "        [1.03900000e+03, 0.00000000e+00]],\n",
       "\n",
       "       [[6.10000000e+01, 1.00000000e+00],\n",
       "        [7.20000000e+01, 1.00000000e+00],\n",
       "        [2.14000000e+02, 1.00000000e+00],\n",
       "        ...,\n",
       "        [9.95000000e+02, 0.00000000e+00],\n",
       "        [9.96000000e+02, 0.00000000e+00],\n",
       "        [9.98000000e+02, 0.00000000e+00]],\n",
       "\n",
       "       [[1.62000000e+02, 1.00000000e+00],\n",
       "        [4.42000000e+02, 9.29318106e-01],\n",
       "        [9.03000000e+02, 7.90062301e-01],\n",
       "        ...,\n",
       "        [6.48000000e+02, 0.00000000e+00],\n",
       "        [6.84000000e+02, 0.00000000e+00],\n",
       "        [7.13000000e+02, 0.00000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.62000000e+02, 1.00000000e+00],\n",
       "        [4.42000000e+02, 9.93432573e-01],\n",
       "        [9.03000000e+02, 9.65903211e-01],\n",
       "        ...,\n",
       "        [1.27000000e+02, 0.00000000e+00],\n",
       "        [1.57000000e+02, 0.00000000e+00],\n",
       "        [3.12000000e+02, 0.00000000e+00]],\n",
       "\n",
       "       [[1.02000000e+03, 1.00000000e+00],\n",
       "        [1.02800000e+03, 1.00000000e+00],\n",
       "        [1.02400000e+03, 9.86083876e-01],\n",
       "        ...,\n",
       "        [9.64000000e+02, 0.00000000e+00],\n",
       "        [9.66000000e+02, 0.00000000e+00],\n",
       "        [9.80000000e+02, 0.00000000e+00]],\n",
       "\n",
       "       [[9.28000000e+02, 1.00000000e+00],\n",
       "        [9.29000000e+02, 1.00000000e+00],\n",
       "        [9.34000000e+02, 1.00000000e+00],\n",
       "        ...,\n",
       "        [1.51000000e+02, 0.00000000e+00],\n",
       "        [1.53000000e+02, 0.00000000e+00],\n",
       "        [1.57000000e+02, 0.00000000e+00]]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "49c19fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"pkdd1998\"\n",
    "# for key in cluster_plot_scores.keys():\n",
    "#     cluster_id = int(key[0][0])\n",
    "#     sub_cluster_id = key[1]\n",
    "#     a,b,c = cluster_plot_scores[key]\n",
    "#     budget =1\n",
    "#     figures = plot(budget,a,b,c,key, outliers = cluster_indices[key], X_index = data_index)\n",
    "#     #lo = LookOut(budget,a,b,c)\n",
    "#     #print(len(lo[0]),len(lo[1]))\n",
    "#    # for budget in range(5):\n",
    "#    #     figures = plot(budget,a,b,c,key)\n",
    "#    #     for i,figure in enumerate(figures):\n",
    "#    #         fname = \"assets/\"+dataset_name+\"/{0}-{1}-{2}-{3}-{4}.png\".format(\"lookout\",cluster_id,sub_cluster_id+1,budget+1, i+1)\n",
    "#    #         figure.savefig(fname,bbox_inches = 'tight')\n",
    "#    #         plt.close(figure)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3eeb704a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('2 clusters',\n",
       "  0): (array([[[1.04300000e+03, 1.00000000e+00],\n",
       "          [1.04900000e+03, 1.00000000e+00],\n",
       "          [1.05200000e+03, 1.00000000e+00],\n",
       "          ...,\n",
       "          [1.03700000e+03, 0.00000000e+00],\n",
       "          [1.03800000e+03, 0.00000000e+00],\n",
       "          [1.03900000e+03, 0.00000000e+00]],\n",
       "  \n",
       "         [[6.10000000e+01, 1.00000000e+00],\n",
       "          [7.20000000e+01, 1.00000000e+00],\n",
       "          [2.14000000e+02, 1.00000000e+00],\n",
       "          ...,\n",
       "          [9.95000000e+02, 0.00000000e+00],\n",
       "          [9.96000000e+02, 0.00000000e+00],\n",
       "          [9.98000000e+02, 0.00000000e+00]],\n",
       "  \n",
       "         [[1.62000000e+02, 1.00000000e+00],\n",
       "          [4.42000000e+02, 9.29318106e-01],\n",
       "          [9.03000000e+02, 7.90062301e-01],\n",
       "          ...,\n",
       "          [6.48000000e+02, 0.00000000e+00],\n",
       "          [6.84000000e+02, 0.00000000e+00],\n",
       "          [7.13000000e+02, 0.00000000e+00]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[1.62000000e+02, 1.00000000e+00],\n",
       "          [4.42000000e+02, 9.93432573e-01],\n",
       "          [9.03000000e+02, 9.65903211e-01],\n",
       "          ...,\n",
       "          [1.27000000e+02, 0.00000000e+00],\n",
       "          [1.57000000e+02, 0.00000000e+00],\n",
       "          [3.12000000e+02, 0.00000000e+00]],\n",
       "  \n",
       "         [[1.02000000e+03, 1.00000000e+00],\n",
       "          [1.02800000e+03, 1.00000000e+00],\n",
       "          [1.02400000e+03, 9.86083876e-01],\n",
       "          ...,\n",
       "          [9.64000000e+02, 0.00000000e+00],\n",
       "          [9.66000000e+02, 0.00000000e+00],\n",
       "          [9.80000000e+02, 0.00000000e+00]],\n",
       "  \n",
       "         [[9.28000000e+02, 1.00000000e+00],\n",
       "          [9.29000000e+02, 1.00000000e+00],\n",
       "          [9.34000000e+02, 1.00000000e+00],\n",
       "          ...,\n",
       "          [1.51000000e+02, 0.00000000e+00],\n",
       "          [1.53000000e+02, 0.00000000e+00],\n",
       "          [1.57000000e+02, 0.00000000e+00]]]), [(4,\n",
       "    [12.0,\n",
       "     [1021.0,\n",
       "      1024.0,\n",
       "      1026.0,\n",
       "      1027.0,\n",
       "      1029.0,\n",
       "      1032.0,\n",
       "      1033.0,\n",
       "      1034.0,\n",
       "      1035.0,\n",
       "      1036.0,\n",
       "      1037.0,\n",
       "      1038.0]]),\n",
       "   (3,\n",
       "    [8.0, [1049.0, 1052.0, 1044.0, 1040.0, 1047.0, 1048.0, 1058.0, 1059.0]]),\n",
       "   (5, [3.980896873842468, [1000.0, 1017.0, 1018.0, 1019.0]]),\n",
       "   (12, [2.959335783855708, [903.0, 162.0, 442.0]]),\n",
       "   (13, [2.0, [1020.0, 1028.0]]),\n",
       "   (6, [1.7084342468895377, [281.0, 226.0]]),\n",
       "   (7, [1.0, [1043.0]])], [4, 3, 5, 12, 13, 6, 7])}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_plot_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa19eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
